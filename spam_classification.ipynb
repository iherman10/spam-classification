{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2870c7c-670d-459a-ac4d-10618934b57f",
   "metadata": {},
   "source": [
    "# Frame the problem and look at the big picture\n",
    "This is exercise #4 from Chapter 3 of Hands-On Machine Learning, which covers classification. \n",
    "\n",
    "1. __Define the objective.__ The task is to build a spam classifier using data from [Apache SpamAssassin's public datasets](https://spamassassin.apache.org/old/publiccorpus/) ([README](https://spamassassin.apache.org/old/publiccorpus/readme.html)). \n",
    "\n",
    "2. __How will your solution be used?__ This could be used by an email service like Gmail to automatically flag and filter out messages that have a high probability of being spam. \n",
    "\n",
    "3. __What are the current solutions/workarounds (if any)?__ Well, spam filters do already exist in most if not all email services. That being said, some spam emails still get through, so it's up to users to identify those on their own. In addition, when a spam email does get through, users can mark it as spam, and all future emails from that address will be automatically marked as spam. \n",
    "\n",
    "4. __How should you frame this problem (supervised/unsupervised, online/offline, etc.)?__ This is a __supervised classification task__ because we are making binary predictions (spam vs. ham) and we have labeled training data. Ideally, this is an online learning task, because spammers never stop thinking of new ways to trick people, so the model should be learning from new data constantly. However, for the sake of this exercise, it will be an offline system using static training data. \n",
    "\n",
    "5. __How should performance be measured?__ This is a bit more complex than the Titanic task, for example, where _accuracy_ was our primary performance metric. Is it better to lean further towards spam and risk misclassifying safe emails as spam? Or is it better to lean further towards \"ham\" and risk missing spam emails?\n",
    "    - According to ChatGPT: \"For a spam classifier, it is generally more fitting to __prioritize precision over recall__.\" This is because a spam classifier that marks safe emails as spam is a real nuisance to users, whereas missing a few spam emails is not as big a deal. By focusing on precision, we will minimize false positives and reduce the chances of misclassifying safe emails. \n",
    "    \n",
    "    - `Precision = TP / (TP + FP)`\n",
    "    \n",
    "    - That being said, __there should also be a minimum recall.__ I could predict just one instance as spam, and if I'm correct, that means my precision is 100%. However, recall would be way too low.  \n",
    "    \n",
    "6. __Is the performance measure aligned with the business objective?__ Yes. Optimizing for precision will reduce the number of false positives, and therefore create a better hypothetical user experience. Since the spam classifier would most likely be used in a commercial product, user experience is the most important thing. \n",
    "\n",
    "7. __What would be the minimum performance needed to reach the business objective?__ It seems that a __precision of 95%__ is the widely recommended benchmark for spam classifiers. Regarding minimum recall, maybe let's see baseline performance of different models to estimate what a realistic minimum might be. \n",
    "\n",
    "8. __What are comparable problems? Can you reuse experience or tools?__ Beyond the Titanic dataset, this is really my first end-to-end classification project. From my work on the [MNIST dataset](https://github.com/iherman10/mnist-classification/blob/main/chapter_3.ipynb), I can reuse some charting function to analyze performance and compare models. From my work on the [Titanic dataset](https://github.com/iherman10/titanic/blob/main/titanic_2.ipynb), I can reuse the custom transformer class structures for data transformation purposes.\n",
    "\n",
    "9. __Is human expertise available?__ The internet :) I'm working on this solo. \n",
    "\n",
    "10. __How would you solve the problem manually?__ When I try to eyeball whether an email is spam or not, I consider:\n",
    "    - Have I received emails from this sender before?\n",
    "    - Are there obvious typos?\n",
    "    - Are there links? \n",
    "    - Are they asking for money? Or credit card information? Etc. \n",
    "    - Are they writing in all caps? Or all lower-case? \n",
    "    \n",
    "    These considerations might influence the feature engineering part of this project. \n",
    "\n",
    "11. __List assumptions you've made so far.__ \n",
    "    - I should be able to identify most spam just by looking at it. \n",
    "    \n",
    "    - I'll have to leverage text transformations to process the data. \n",
    "    \n",
    "    - Baseline models should get me most of the way towards my performance goal, and feature engineering/hyperparameter tuning will get me the rest of the way.  \n",
    "\n",
    "12. __Verify assumptions if possible.__ TBD..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4cab1e55-f245-4a14-80f0-fc71f9d06f48",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://artifacts-prod-use1.pinadmin.com/artifactory/api/pypi/pinterest-python-pip-prod-virtual/simple/\n",
      "Requirement already satisfied: urlextract in /Users/iherman/anaconda3/lib/python3.11/site-packages (1.8.0)\n",
      "Requirement already satisfied: idna in /Users/iherman/anaconda3/lib/python3.11/site-packages (from urlextract) (3.4)\n",
      "Requirement already satisfied: uritools in /Users/iherman/anaconda3/lib/python3.11/site-packages (from urlextract) (4.0.2)\n",
      "Requirement already satisfied: platformdirs in /Users/iherman/anaconda3/lib/python3.11/site-packages (from urlextract) (2.5.2)\n",
      "Requirement already satisfied: filelock in /Users/iherman/anaconda3/lib/python3.11/site-packages (from urlextract) (3.9.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Libraries \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "import os\n",
    "import tarfile \n",
    "import urllib.request\n",
    "\n",
    "import joblib\n",
    "\n",
    "import email \n",
    "import email.policy\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import re \n",
    "import html\n",
    "import nltk\n",
    "\n",
    "# Use % to install in currently running environment, not ! \n",
    "%pip install urlextract\n",
    "import urlextract\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c9d787-66d7-487b-827a-51873a74130c",
   "metadata": {},
   "source": [
    "# Get the data\n",
    "Available data from SpamAssassin website: \n",
    "- `spam`: 500 spam messages \n",
    "- `spam_2`: 1396 spam messages, added more recently. \n",
    "- `easy_ham`: 2500 non-spam messages, fairly easy to differentiate.  \n",
    "- `easy_ham_2`: 144 non-spam messages, added more recently. \n",
    "- `hard_ham`: 250 non-spam messages, harder to differentiate. \n",
    "\n",
    "In total, there are __6046__ messages with about a 31% spam ratio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5506ba1-2df8-4fce-922e-16449ec8cb1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download data \n",
    "DOWNLOAD_ROOT = 'http://spamassassin.apache.org/old/publiccorpus/'\n",
    "\n",
    "SPAM_URL = DOWNLOAD_ROOT + '20030228_spam.tar.bz2'\n",
    "SPAM_2_URL = DOWNLOAD_ROOT + '20050311_spam_2.tar.bz2'\n",
    "EASY_HAM_URL = DOWNLOAD_ROOT + '20030228_easy_ham.tar.bz2'\n",
    "EASY_HAM_2_URL = DOWNLOAD_ROOT + '20030228_easy_ham_2.tar.bz2'\n",
    "HARD_HAM_URL = DOWNLOAD_ROOT + '20030228_hard_ham.tar.bz2'\n",
    "\n",
    "SPAM_PATH = os.path.join('datasets', 'spam')\n",
    "\n",
    "def fetch_spam_data(spam_url=SPAM_URL, \n",
    "                    spam_2_url=SPAM_2_URL, \n",
    "                    easy_ham_url=EASY_HAM_URL, \n",
    "                    easy_ham_2_url=EASY_HAM_2_URL, \n",
    "                    hard_ham_url=HARD_HAM_URL,  \n",
    "                    spam_path=SPAM_PATH):\n",
    "    if not os.path.isdir(spam_path):\n",
    "        os.makedirs(spam_path)\n",
    "    for filename, url in (('spam.tar.bz2', SPAM_URL), \n",
    "                          ('spam_2.tar.bz2', SPAM_2_URL), \n",
    "                          ('easy_ham.tar.bz2', EASY_HAM_URL), \n",
    "                          ('easy_ham_2.tar.bz2', EASY_HAM_2_URL), \n",
    "                          ('hard_ham.tar.bz2', HARD_HAM_URL)):\n",
    "        path = os.path.join(spam_path, filename)\n",
    "        if not os.path.isfile(path):\n",
    "            urllib.request.urlretrieve(url, path)\n",
    "        tar_bz2_file = tarfile.open(path)\n",
    "        tar_bz2_file.extractall(path=spam_path)\n",
    "        tar_bz2_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81a14d30-4e71-47e3-9798-8ca2b9a1647a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fetch_spam_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "816a460b-ded1-493f-a09f-ca05f32f5c84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load all the emails \n",
    "SPAM_DIR = os.path.join(SPAM_PATH, 'spam')\n",
    "SPAM_2_DIR = os.path.join(SPAM_PATH, 'spam_2')\n",
    "EASY_HAM_DIR = os.path.join(SPAM_PATH, 'easy_ham')\n",
    "EASY_HAM_2_DIR = os.path.join(SPAM_PATH, 'easy_ham_2')\n",
    "HARD_HAM_DIR = os.path.join(SPAM_PATH, 'hard_ham')\n",
    "\n",
    "spam_filenames = [name for name in sorted(os.listdir(SPAM_DIR)) if len(name) > 20]\n",
    "spam_2_filenames = [name for name in sorted(os.listdir(SPAM_2_DIR)) if len(name) > 20]\n",
    "easy_ham_filenames = [name for name in sorted(os.listdir(EASY_HAM_DIR)) if len(name) > 20]\n",
    "easy_ham_2_filenames = [name for name in sorted(os.listdir(EASY_HAM_2_DIR)) if len(name) > 20]\n",
    "hard_ham_filenames = [name for name in sorted(os.listdir(HARD_HAM_DIR)) if len(name) > 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "057a321c-00e9-41cb-a061-ac6d0b46b3b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "spam: 500 files\n",
      "spam_2: 1396 files\n",
      "easy_ham: 2500 files\n",
      "easy_ham_2: 1400 files \n",
      "hard_ham: 250 files \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "spam: {len(spam_filenames)} files\n",
    "spam_2: {len(spam_2_filenames)} files\n",
    "easy_ham: {len(easy_ham_filenames)} files\n",
    "easy_ham_2: {len(easy_ham_2_filenames)} files \n",
    "hard_ham: {len(hard_ham_filenames)} files \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fa3c579-3c3c-4f6f-af39-d313fa7bfa83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parse emails \n",
    "def load_email(directory, filename, spam_path=SPAM_PATH):\n",
    "    with open(os.path.join(spam_path, directory, filename), \"rb\") as f:\n",
    "        return email.parser.BytesParser(policy=email.policy.default).parse(f)\n",
    "    \n",
    "spam_emails = [load_email(directory='spam', filename=name) for name in spam_filenames]\n",
    "spam_2_emails = [load_email(directory='spam_2', filename=name) for name in spam_2_filenames]\n",
    "easy_ham_emails = [load_email(directory='easy_ham', filename=name) for name in easy_ham_filenames]\n",
    "easy_ham_2_emails = [load_email(directory='easy_ham_2', filename=name) for name in easy_ham_2_filenames]\n",
    "hard_ham_emails = [load_email(directory='hard_ham', filename=name) for name in hard_ham_filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b50bf387-21b5-470f-8d8f-f2695a92e232",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create train and test sets \n",
    "X = np.array(spam_emails \\\n",
    "             + spam_2_emails \\\n",
    "             + easy_ham_emails \\\n",
    "             + easy_ham_2_emails \\\n",
    "             + hard_ham_emails \\\n",
    "             , dtype=object)\n",
    "\n",
    "y = np.array([1] * len(spam_emails) \\\n",
    "             + [1] * len(spam_2_emails) \\\n",
    "             + [0] * len(easy_ham_emails) \\\n",
    "             + [0] * len(easy_ham_2_emails) \\\n",
    "             + [0] * len(hard_ham_emails))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc3bcec-eb88-459b-bf91-4016660f753e",
   "metadata": {},
   "source": [
    "# Explore the data\n",
    "Let's start by examining examples of ham vs. spam to understand what the data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae695bd2-c803-4352-8b5d-dc4d85bc429b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Martin A posted:\n",
      "Tassos Papadopoulos, the Greek sculptor behind the plan, judged that the\n",
      " limestone of Mount Kerdylio, 70 miles east of Salonika and not far from the\n",
      " Mount Athos monastic community, was ideal for the patriotic sculpture. \n",
      " \n",
      " As well as Alexander's granite features, 240 ft high and 170 ft wide, a\n",
      " museum, a restored amphitheatre and car park for admiring crowds are\n",
      "planned\n",
      "---------------------\n",
      "So is this mountain limestone or granite?\n",
      "If it's limestone, it'll weather pretty fast.\n",
      "\n",
      "------------------------ Yahoo! Groups Sponsor ---------------------~-->\n",
      "4 DVDs Free +s&p Join Now\n",
      "http://us.click.yahoo.com/pt6YBB/NXiEAA/mG3HAA/7gSolB/TM\n",
      "---------------------------------------------------------------------~->\n",
      "\n",
      "To unsubscribe from this group, send an email to:\n",
      "forteana-unsubscribe@egroups.com\n",
      "\n",
      " \n",
      "\n",
      "Your use of Yahoo! Groups is subject to http://docs.yahoo.com/info/terms/\n"
     ]
    }
   ],
   "source": [
    "# Ham\n",
    "print(easy_ham_emails[1].get_content().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "517389dd-5b8d-44b8-aba3-c44a2c5937ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help wanted.  We are a 14 year old fortune 500 company, that is\n",
      "growing at a tremendous rate.  We are looking for individuals who\n",
      "want to work from home.\n",
      "\n",
      "This is an opportunity to make an excellent income.  No experience\n",
      "is required.  We will train you.\n",
      "\n",
      "So if you are looking to be employed from home with a career that has\n",
      "vast opportunities, then go:\n",
      "\n",
      "http://www.basetel.com/wealthnow\n",
      "\n",
      "We are looking for energetic and self motivated people.  If that is you\n",
      "than click on the link and fill out the form, and one of our\n",
      "employement specialist will contact you.\n",
      "\n",
      "To be removed from our link simple go to:\n",
      "\n",
      "http://www.basetel.com/remove.html\n",
      "\n",
      "\n",
      "4139vOLW7-758DoDY1425FRhM1-764SMFc8513fCsLl40\n"
     ]
    }
   ],
   "source": [
    "# Spam\n",
    "print(spam_emails[6].get_content().strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570a8e2a-e9d1-4246-9fa4-ae96f74d4423",
   "metadata": {},
   "source": [
    "Some emails are multipart, with images and attachments. Let's look at different types of structures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e6c2431-e1f6-44c4-bce8-4ef2d4cf7dda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_email_structure(email):\n",
    "    if isinstance(email, str):\n",
    "        return email \n",
    "    payload = email.get_payload()\n",
    "    if isinstance(payload, list):\n",
    "        return f'multipart({\", \".join([get_email_structure(sub_email) for sub_email in payload])})'\n",
    "    else:\n",
    "        return email.get_content_type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cda15fd5-b441-4039-8e23-bbcb659e2a6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def structures_counter(emails):\n",
    "    structures = Counter()\n",
    "    for email in emails:\n",
    "        structure = get_email_structure(email)\n",
    "        structures[structure] += 1\n",
    "    return structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ac16c80-ec89-439b-a107-779047b681eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('text/plain', 2408),\n",
       " ('multipart(text/plain, application/pgp-signature)', 66),\n",
       " ('multipart(text/plain, text/html)', 8),\n",
       " ('multipart(text/plain, text/plain)', 4),\n",
       " ('multipart(text/plain)', 3),\n",
       " ('multipart(text/plain, application/octet-stream)', 2),\n",
       " ('multipart(text/plain, text/enriched)', 1),\n",
       " ('multipart(text/plain, application/ms-tnef, text/plain)', 1),\n",
       " ('multipart(multipart(text/plain, text/plain, text/plain), application/pgp-signature)',\n",
       "  1),\n",
       " ('multipart(text/plain, video/mng)', 1),\n",
       " ('multipart(text/plain, multipart(text/plain))', 1),\n",
       " ('multipart(text/plain, application/x-pkcs7-signature)', 1),\n",
       " ('multipart(text/plain, multipart(text/plain, text/plain), text/rfc822-headers)',\n",
       "  1),\n",
       " ('multipart(text/plain, multipart(text/plain, text/plain), multipart(multipart(text/plain, application/x-pkcs7-signature)))',\n",
       "  1),\n",
       " ('multipart(text/plain, application/x-java-applet)', 1)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structures_counter(easy_ham_emails).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8519ac60-38ce-41ce-ad78-5d8282410ea8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('text/plain', 218),\n",
       " ('text/html', 183),\n",
       " ('multipart(text/plain, text/html)', 45),\n",
       " ('multipart(text/html)', 20),\n",
       " ('multipart(text/plain)', 19),\n",
       " ('multipart(multipart(text/html))', 5),\n",
       " ('multipart(text/plain, image/jpeg)', 3),\n",
       " ('multipart(text/html, application/octet-stream)', 2),\n",
       " ('multipart(text/plain, application/octet-stream)', 1),\n",
       " ('multipart(text/html, text/plain)', 1),\n",
       " ('multipart(multipart(text/html), application/octet-stream, image/jpeg)', 1),\n",
       " ('multipart(multipart(text/plain, text/html), image/gif)', 1),\n",
       " ('multipart/alternative', 1)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structures_counter(spam_emails).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b1d1ab-5b01-4243-87b3-c7c5448a49c3",
   "metadata": {},
   "source": [
    "It seems that ham emails are more often plan text, while spam has a lot of html. Also, a lot of ham emails are signed using \"pgp\", while no spam is. Email structure might be an important feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f02413eb-2626-4468-9832-b4a667f14d67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return-Path : <12a1mailbot1@web.de>\n",
      "Delivered-To : zzzz@localhost.spamassassin.taint.org\n",
      "Received : from localhost (localhost [127.0.0.1])\tby phobos.labs.spamassassin.taint.org (Postfix) with ESMTP id 136B943C32\tfor <zzzz@localhost>; Thu, 22 Aug 2002 08:17:21 -0400 (EDT)\n",
      "Received : from mail.webnote.net [193.120.211.219]\tby localhost with POP3 (fetchmail-5.9.0)\tfor zzzz@localhost (single-drop); Thu, 22 Aug 2002 13:17:21 +0100 (IST)\n",
      "Received : from dd_it7 ([210.97.77.167])\tby webnote.net (8.9.3/8.9.3) with ESMTP id NAA04623\tfor <zzzz@spamassassin.taint.org>; Thu, 22 Aug 2002 13:09:41 +0100\n",
      "From : 12a1mailbot1@web.de\n",
      "Received : from r-smtp.korea.com - 203.122.2.197 by dd_it7  with Microsoft SMTPSVC(5.5.1775.675.6);\t Sat, 24 Aug 2002 09:42:10 +0900\n",
      "To : dcek1a1@netsgo.com\n",
      "Subject : Life Insurance - Why Pay More?\n",
      "Date : Wed, 21 Aug 2002 20:31:57 -1600\n",
      "MIME-Version : 1.0\n",
      "Message-ID : <0103c1042001882DD_IT7@dd_it7>\n",
      "Content-Type : text/html; charset=\"iso-8859-1\"\n",
      "Content-Transfer-Encoding : quoted-printable\n"
     ]
    }
   ],
   "source": [
    "# Examine email headers \n",
    "for header, value in spam_emails[0].items():\n",
    "    print(header, ':', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fbfddb04-4d02-4836-a012-d46276f84377",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Life Insurance - Why Pay More?'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just look at the Subject header\n",
    "spam_emails[0]['Subject']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609b5da5-0eb4-4ebf-a474-52ddb662245c",
   "metadata": {},
   "source": [
    "## Email to text transformations\n",
    "The emails are easiest to work with in plain text format. We need some functions to transform emails. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c32df573-6415-4b4e-b7a9-0a7e12df43fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to convert html part to plain text \n",
    "def convert_html_to_plain_text(html_content):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "    # Remove <head> section\n",
    "    if soup.head:\n",
    "        soup.head.decompose()\n",
    "        \n",
    "    # Replace <a> tags with \"HYPERLINK\"\n",
    "    for a in soup.find_all('a'):\n",
    "        a.string = 'HYPERLINK'\n",
    "\n",
    "    plaintext = soup.get_text() # Get rid of all HTML tags and get plaintext\n",
    "    plaintext = re.sub(r'\\n\\s*\\n', '\\n', plaintext) # Replace multiple newlines with single newline\n",
    "    plaintext = html.unescape(plaintext) # Unescape HTML entities\n",
    "    return plaintext "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b447255-d0da-4e29-b46e-680de3ccf5f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*This message was transferred with a trial version of CommuniGate(tm) Pro*\n",
      "<HTML><FONT  BACK=\"#ffffff\" style=\"BACKGROUND-COLOR: #ffffff\" SIZE=2 PTSIZE=10><B width=\"163\" height=\"255\"></b></FONT><B width=\"163\" height=\"255\"><FONT  COLOR=\"#008000\" BACK=\"#ffffff\" style=\"BACKGROUND-COLOR: #ffffff\" SIZE=3 PTSIZE=12 FAMILY=\"SANSSERIF\" FACE=\"Arial\" LANG=\"0\"><B>Missed all the news this weekend? </FONT><FONT  COLOR=\"#008080\" BACK=\"#ffffff\" style=\"BACKGROUND-COLOR: #ffffff\" SIZE=3 PTSIZE=12 FAMILY=\"SANSSERIF\" FACE=\"Arial\" LANG=\"0\"></B> </FONT><FONT  COLOR=\"#008080\" BACK=\"#ffffff\" style=\"BACKGROUND-COLOR: #ffffff\" SIZE=2 PTSIZE=10 FAMILY=\"SANSSERIF\" FACE=\"Arial\" LANG=\"0\"><BR>\n",
      "<IMG src=\"http://www.lordoftheringsaudio.com/images/mixed/complete.jpg\" <BR width=\"213\" height=\"335\">\n",
      "<BR>\n",
      "<B width=\"163\" height=\"255\"></b></FONT>\n",
      "<B width=\"163\" height=\"255\"><FONT  COLOR=\"#008000\" BACK=\"#ffffff\" style=\"BACKGROUND-COLOR: #ffffff\" SIZE=3 PTSIZE=12 FAMILY=\"SANSSERIF\" FACE=\"Arial\" LANG=\"0\"><B>Were you too busy tr ...\n"
     ]
    }
   ],
   "source": [
    "html_spam_emails = [email for email in X_train[y_train==1] if get_email_structure(email) == 'text/html']\n",
    "sample_html_spam = html_spam_emails[1].get_content().strip()[:1000]\n",
    "print(sample_html_spam, '...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70d265dd-7303-4680-b05c-3f22f4ebb469",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*This message was transferred with a trial version of CommuniGate(tm) Pro*\n",
      "Missed all the news this weekend?  \n",
      "Were you too busy tr ...\n"
     ]
    }
   ],
   "source": [
    "print(convert_html_to_plain_text(sample_html_spam), '...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1e51355-d172-4b67-a922-0273d7eb77ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to convert entire email to plaintext \n",
    "def convert_email_to_plain_text(email):\n",
    "    plain_text_parts = []\n",
    "    \n",
    "    for part in email.walk():\n",
    "        content_type = part.get_content_type()\n",
    "        \n",
    "        if content_type == 'text/plain':\n",
    "            plain_text_parts.append(part.get_content())\n",
    "            \n",
    "        elif content_type == 'text/html':\n",
    "            plain_text_parts.append(convert_html_to_plain_text(part.get_content()))\n",
    "            \n",
    "    plaintext = '\\n'.join(plain_text_parts)\n",
    "    return plaintext "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "addb3e86-4062-4b0b-9ed4-e8dbfb3105fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<email.message.EmailMessage at 0x15e9efc10>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_spam = X_train[y_train==1][0]\n",
    "sample_spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81ab9ca2-500b-45eb-8353-d4109dcee170",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \t\n",
      "Asset Marketing Systems\n",
      "is the insurance industry's fastest growing Field Marketing Organization\n",
      "over the past four years. This year we'll place $1.5 billion in premium,\n",
      "selling high-quality, high-commission fixed annuities to America's 35\n",
      "million Senior Citizens.\n",
      "\n",
      "\t \t\n",
      "\n",
      "Why have so many Agents chosen to do business with Asset Marketing\n",
      "Systems?\n",
      "Asset Marketing is the only FMO in America that generates qualified\n",
      "leads, helps set appointments, structures product positioning, increases\n",
      "closing ratios and handles all the paperwork... at absolutely no cost to\n",
      "the Agent!\n",
      "\n",
      "We are also proud to report our Agents routinely earn 20 times the\n",
      "industry average. Assuming you qualify, we'll pick up the entire tab for\n",
      "you to visit our corporate offices in sunny San Diego.\n",
      "\t\n",
      " One phone call can change your life. Guaranteed.\t\n",
      "\n",
      "Ready to join the Best? Call Susan at\n",
      " 888-303-8755\n",
      "or e-mail Jennifer at jennifer@assetmarketingsystems.com\n",
      "<mailto:jennifer@assetmarketingsystems.com> \n",
      "? or ?\n",
      "\n",
      "Please fill out the form below for more information\t \n",
      "Name:\t  \t\n",
      "E-mail:\t  \t\n",
      "Phone:\t  \t\n",
      "City:\t  \tState:\t  \t \t\n",
      " \t  \t \t   \t\n",
      " \n",
      "\n",
      "Asset Marketing Systems <http://www.assetmarketingsystems.com> \n",
      "  \t\n",
      "We do not want anyone to receive our mailings who does not wish to. This\n",
      "is professional communication sent to insurance professionals. To be\n",
      "removed from this mailing list, DO NOT REPLY to this message. Instead,\n",
      "go here: http://www.Insurancemail.net \t\n",
      "Legal Notice <http://www.insiq.com/legal.htm>  \n",
      "\n",
      "\n",
      "                  Asset Marketing Systems\n",
      "is the insurance industry's fastest \n",
      "                  growing Field Marketing Organization over the past four years. \n",
      "                  This year we'll place $1.5 billion in premium, selling high-quality, \n",
      "                  high-commission fixed annuities to America's 35 million Senior \n",
      "                  Citizens.\n",
      "            Why have so many Agents chosen to do business with Asset Marketing \n",
      "            Systems?\n",
      "            Asset Marketing is the only FMO in America that\n",
      "            generates qualified leads, helps set appointments, structures \n",
      "            product positioning, increases closing ratios and handles all the \n",
      "            paperwork... at absolutely no cost to the Agent!\n",
      "            We are also proud to report \n",
      "            our Agents routinely earn 20 times the industry average. Assuming \n",
      "            you qualify, we'll pick up the entire tab for you to visit our corporate \n",
      "            offices in sunny San Diego.\n",
      "Ready to join the Best? Call Susan at\n",
      "            or e-mail Jennifer at HYPERLINK\n",
      "            — or —\n",
      "Please fill out the form below for more information\n",
      "Name:\n",
      "E-mail:\n",
      "Phone:\n",
      "City:\n",
      "State:\n",
      "HYPERLINK\n",
      "We \n",
      "            do not want anyone to receive our mailings who does not wish to. This \n",
      "            is professional communication sent to insurance professionals. To \n",
      "            be removed from this mailing list, DO NOT REPLY to this message. Instead, \n",
      "            go here: HYPERLINK\n",
      "HYPERLINK\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(convert_email_to_plain_text(sample_spam))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28835a69-bfa2-4b37-a82b-8a7a2f2085dc",
   "metadata": {},
   "source": [
    "## Stemming\n",
    "Stemming is the process of reducing inflected (or derived) words to their word stem/base/root. E.g. _cat_ from _cats/catlike/catty_. \n",
    "\n",
    "We can use the Natural Language Toolkit ([NLTK](https://www.nltk.org/)) to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "292a93fd-71b5-4163-a7d7-73696ce90736",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computations => comput\n",
      "Computation => comput\n",
      "Computing => comput\n",
      "Computed => comput\n",
      "Compute => comput\n",
      "Compulsive => compuls\n"
     ]
    }
   ],
   "source": [
    "stemmer = nltk.PorterStemmer()\n",
    "for word in (\"Computations\", \"Computation\", \"Computing\", \"Computed\", \"Compute\", \"Compulsive\"):\n",
    "    print(word, '=>', stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802f020c-fef6-49bb-ba77-f3c71aca6f97",
   "metadata": {},
   "source": [
    "## Finding URLs\n",
    "We want to replace URLs with the word \"URL\". We can use the the `urlextract` library to do this intead of regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2434bf00-86d6-4990-a8c6-2dab856c4e11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['github.com', 'https://youtu.be/7Pq-S557XQU?t=3m32s']\n"
     ]
    }
   ],
   "source": [
    "url_extractor = urlextract.URLExtract()\n",
    "print(url_extractor.find_urls(\"Will it detect github.com and https://youtu.be/7Pq-S557XQU?t=3m32s\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0119895a-8ddc-4b1a-998a-8fe99bbc15ae",
   "metadata": {},
   "source": [
    "# Prepare the data\n",
    "Let's create custom transformer classes to implement the transformations we tested above. Ultimately, the goal is to convert each email into a sparse vector that indicates the presence or absence of each possible word. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1039448f-c28c-4c58-a1a5-7b9208c3dad6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EmailToWordCounterTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, strip_headers=True, lower_case=True, remove_punctuation=True, replace_urls=True, replace_numbers=True, stemming=True):\n",
    "        self.strip_headers = strip_headers\n",
    "        self.lower_case = lower_case\n",
    "        self.remove_punctuation = remove_punctuation\n",
    "        self.replace_urls = replace_urls\n",
    "        self.replace_numbers = replace_numbers\n",
    "        self.stemming = stemming\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self \n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_transformed = []\n",
    "        for email in X:\n",
    "            text = convert_email_to_plain_text(email) or \"\"\n",
    "            \n",
    "            if self.lower_case:\n",
    "                text = text.lower()\n",
    "                \n",
    "            if self.replace_urls and url_extractor is not None:\n",
    "                urls = list(set(url_extractor.find_urls(text)))\n",
    "                urls.sort(key=lambda url: len(url), reverse=True)\n",
    "                for url in urls:\n",
    "                    text = text.replace(url, \" URL \")\n",
    "            \n",
    "            if self.replace_numbers:\n",
    "                text = re.sub(r'\\d+(?:\\.\\d*)?(?:[eE][+-]?\\d+)?', 'NUMBER', text)\n",
    "                \n",
    "            if self.remove_punctuation:\n",
    "                text = re.sub(r'\\W+', ' ', text, flags=re.M)\n",
    "                \n",
    "            word_counts = Counter(text.split())\n",
    "            \n",
    "            if self.stemming and stemmer is not None:\n",
    "                stemmed_word_counts = Counter()\n",
    "                for word, count in word_counts.items():\n",
    "                    stemmed_word = stemmer.stem(word)\n",
    "                    stemmed_word_counts[stemmed_word] += count\n",
    "                word_counts = stemmed_word_counts\n",
    "            \n",
    "            X_transformed.append(word_counts)\n",
    "        return np.array(X_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e5d8b8f1-e6e9-4d51-96bb-87971f551f2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([Counter({'it': 8, 'number': 6, 'no': 6, 'i': 4, 'new': 4, 'a': 3, 'for': 3, 'don': 3, 't': 3, 'url': 2, 'think': 2, 'about': 2, 'not': 2, 'out': 2, 'next': 2, 'if': 2, 'said': 2, 'stop': 2, 'do': 2, 'even': 2, 'date': 1, 'numbertnumb': 1, 'am': 1, 'get': 1, 'mac': 1, 'ani': 1, 'good': 1, 'reason': 1, 'though': 1, 'll': 1, 'tri': 1, 'to': 1, 'wait': 1, 'one': 1, 'of': 1, 'the': 1, 'ibook': 1, 'rumor': 1, 'spring': 1, 'powerbook': 1, 'month': 1, 'model': 1, 'come': 1, 's': 1, 'realli': 1, 'bad': 1, 'idea': 1, 'geez': 1, 'ha': 1, 'an': 1, 'cooler': 1, 'monitor': 1, 'or': 1}),\n",
       "       Counter({'to': 22, 'the': 18, 'market': 9, 'number': 9, 'thi': 8, 'we': 8, 'mail': 8, 'asset': 7, 'is': 6, 'in': 6, 'agent': 6, 'do': 6, 'at': 6, 'our': 6, 'not': 6, 'system': 5, 'insur': 4, 'industri': 4, 's': 4, 'year': 4, 'll': 4, 'high': 4, 'america': 4, 'qualifi': 4, 'you': 4, 'for': 4, 'or': 4, 'e': 4, 'jennif': 4, 'profession': 4, 'hyperlink': 4, 'phone': 3, 'call': 3, 'url': 3, 'fastest': 2, 'grow': 2, 'field': 2, 'organ': 2, 'over': 2, 'past': 2, 'four': 2, 'place': 2, 'billion': 2, 'premium': 2, 'sell': 2, 'qualiti': 2, 'commiss': 2, 'fix': 2, 'annuiti': 2, 'million': 2, 'senior': 2, 'citizen': 2, 'whi': 2, 'have': 2, 'so': 2, 'mani': 2, 'chosen': 2, 'busi': 2, 'with': 2, 'onli': 2, 'fmo': 2, 'that': 2, 'gener': 2, 'lead': 2, 'help': 2, 'set': 2, 'appoint': 2, 'structur': 2, 'product': 2, 'posit': 2, 'increas': 2, 'close': 2, 'ratio': 2, 'and': 2, 'handl': 2, 'all': 2, 'paperwork': 2, 'absolut': 2, 'no': 2, 'cost': 2, 'are': 2, 'also': 2, 'proud': 2, 'report': 2, 'routin': 2, 'earn': 2, 'time': 2, 'averag': 2, 'assum': 2, 'pick': 2, 'up': 2, 'entir': 2, 'tab': 2, 'visit': 2, 'corpor': 2, 'offic': 2, 'sunni': 2, 'san': 2, 'diego': 2, 'readi': 2, 'join': 2, 'best': 2, 'susan': 2, 'assetmarketingsystem': 2, 'com': 2, 'pleas': 2, 'fill': 2, 'out': 2, 'form': 2, 'below': 2, 'more': 2, 'inform': 2, 'name': 2, 'citi': 2, 'state': 2, 'want': 2, 'anyon': 2, 'receiv': 2, 'who': 2, 'doe': 2, 'wish': 2, 'commun': 2, 'sent': 2, 'be': 2, 'remov': 2, 'from': 2, 'list': 2, 'repli': 2, 'messag': 2, 'instead': 2, 'go': 2, 'here': 2, 'one': 1, 'can': 1, 'chang': 1, 'your': 1, 'life': 1, 'guarante': 1, 'mailto': 1, 'legal': 1, 'notic': 1}),\n",
       "       Counter({'you': 2, 'hyperlink': 2, 'i': 1, 'will': 1, 'show': 1, 'how': 1, 'can': 1, 'quickli': 1, 'and': 1, 'easili': 1, 'improv': 1, 'your': 1, 'credit': 1, 'to': 1, 'a': 1, 'perfect': 1, 'rate': 1})],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test on a few emails \n",
    "X_few = X_train[:3]\n",
    "X_few_wordcounts = EmailToWordCounterTransformer().fit_transform(X_few)\n",
    "X_few_wordcounts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2d790d-98ab-4f50-9b1c-32b3f399415d",
   "metadata": {},
   "source": [
    "# Shortlist promising models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa21dec3-0ec5-45e1-b92f-b80e9ba5ce5b",
   "metadata": {},
   "source": [
    "# Fine-tune the system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb663123-9e29-42db-ab73-3eb1a8ebe3eb",
   "metadata": {},
   "source": [
    "# Present your solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7fcbfb-5550-4c28-9741-d6af9cc1f25b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
